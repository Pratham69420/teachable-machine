<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Mini Teachable Machine</title>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/knn-classifier"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet"></script>
<style>
body {
  font-family: Arial, sans-serif;
  background: #f7f7f7;
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: column;
  align-items: center;
}
h2 { margin: 20px 0; }
.container {
  display: flex;
  flex-wrap: wrap;
  justify-content: center;
  gap: 20px;
  max-width: 900px;
  width: 100%;
}
.class-card {
  background: white;
  border-radius: 15px;
  padding: 15px;
  width: 200px;
  box-shadow: 0 4px 10px rgba(0,0,0,0.2);
  display: flex;
  flex-direction: column;
  align-items: center;
}
.class-card button {
  padding: 10px 15px;
  margin-top: 10px;
  border: none;
  border-radius: 10px;
  cursor: pointer;
  background: #4caf50;
  color: white;
  font-weight: bold;
}
.class-card button:hover { background: #45a049; }
.class-counter { margin-top: 5px; font-size: 14px; color: #333; }
#webcam {
  border-radius: 15px;
  width: 320px;
  max-width: 90%;
  margin-top: 20px;
  box-shadow: 0 4px 15px rgba(0,0,0,0.3);
}
#result {
  margin-top: 20px;
  font-size: 22px;
  font-weight: bold;
  color: #444;
}
#imageInput {
  margin-top: 15px;
}
#cameraControls {
  margin: 15px 0;
  display: flex;
  gap: 10px;
  flex-wrap: wrap;
}
button, select { cursor: pointer; border-radius: 10px; padding: 10px; font-size: 16px; border: none; box-shadow: 0 3px 10px rgba(0,0,0,0.2); }
button:hover, select:hover { transform: scale(1.05); transition: 0.2s; }
</style>
</head>
<body>
<h2>Mini Teachable Machine</h2>

<div class="container">
  <div class="class-card">
    <div>Class 1</div>
    <button onclick="addExample(0)">Add Example</button>
    <div class="class-counter" id="count0">0 examples</div>
  </div>
  <div class="class-card">
    <div>Class 2</div>
    <button onclick="addExample(1)">Add Example</button>
    <div class="class-counter" id="count1">0 examples</div>
  </div>
  <div class="class-card">
    <div>Class 3</div>
    <button onclick="addExample(2)">Add Example</button>
    <div class="class-counter" id="count2">0 examples</div>
  </div>
</div>

<video id="webcam" autoplay playsinline></video>
<div id="cameraControls"></div>

<div>
  <input type="file" id="imageInput" accept="image/*">
</div>

<p id="result">Prediction: none</p>

<script>
const webcam = document.getElementById('webcam');
const result = document.getElementById('result');
const counters = [document.getElementById("count0"), document.getElementById("count1"), document.getElementById("count2")];
const cameraControls = document.getElementById("cameraControls");
const imageInput = document.getElementById("imageInput");

let net, classifier;
let exampleCounts = [0,0,0];
let currentStream;
let facingMode = "user";
let deviceId = null;
let isPhone = true;
let videoDevices = [];

// Setup webcam stream
async function setupCamera() {
  if(currentStream) currentStream.getTracks().forEach(track=>track.stop());
  const constraints = isPhone ? { video: { facingMode } } : { video: { deviceId: { exact: deviceId } } };
  currentStream = await navigator.mediaDevices.getUserMedia(constraints);
  webcam.srcObject = currentStream;
}

// Add example from webcam
async function addExample(classId) {
  const activation = net.infer(webcam,'conv_preds');
  classifier.addExample(activation,classId);
  exampleCounts[classId]++;
  counters[classId].innerText = `${exampleCounts[classId]} examples`;
}

// Predict from webcam
async function predictWebcam() {
  while(true){
    if(classifier.getNumClasses()>0){
      const activation = net.infer(webcam,'conv_preds');
      const prediction = await classifier.predictClass(activation);
      result.innerText = `Prediction: Class ${parseInt(prediction.label)+1}`;
    }
    await tf.nextFrame();
  }
}

// Predict from uploaded image
imageInput.addEventListener('change', async (e)=>{
  const file = e.target.files[0];
  if(!file) return;
  const img = new Image();
  img.src = URL.createObjectURL(file);
  img.onload = async ()=>{
    const activation = net.infer(img,'conv_preds');
    const prediction = await classifier.predictClass(activation);
    result.innerText = `Prediction (image): Class ${parseInt(prediction.label)+1}`;
  }
});

// Switch front/back camera for phones
async function switchCamera() {
  facingMode = (facingMode==="user") ? "environment" : "user";
  await setupCamera();
}

// Change camera on computers
async function changeCamera(newDeviceId) {
  deviceId = newDeviceId;
  await setupCamera();
}

// Setup camera controls based on device
async function setupCameraControls() {
  const devices = await navigator.mediaDevices.enumerateDevices();
  videoDevices = devices.filter(d=>d.kind==='videoinput');

  // Heuristic: if only one video device or mobile device, treat as phone
  isPhone = videoDevices.length <= 2 && /Mobi|Android/i.test(navigator.userAgent);

  if(isPhone){
    cameraControls.innerHTML = `<button onclick="switchCamera()">ðŸ”„ Switch Camera</button>`;
    await setupCamera();
  } else {
    let selectHtml = `<select onchange="changeCamera(this.value)">`;
    videoDevices.forEach(d=>{
      selectHtml += `<option value="${d.deviceId}">${d.label || 'Camera'}</option>`;
    });
    selectHtml += `</select>`;
    cameraControls.innerHTML = selectHtml;
    deviceId = videoDevices[0].deviceId;
    await setupCamera();
  }
}

// Initialize model and camera
async function setup() {
  net = await mobilenet.load();
  classifier = knnClassifier.create();
  await setupCameraControls();
  predictWebcam();
}

setup();
</script>
</body>
</html>
